주연님)
전처리 3가지 정도하였음. 
X_4 범주로 처리 후 가변수화
X_23 범주로 처리 후 가변수화
X_50 ~ 56 이상치 평균치로 처리 or 선형보간법
X_10, X_11  어떻게 처리 해야할지 고민중

현지님)
트레인 셋 테스트셋 분할
모델 돌리기 전까지 좀 더 데이터 파악해야할 필요성을 느낌.
모델은 랜덤 포레스트로 돌릴려고 하고있음. 


우근님)
조언을 구하고자함. 
각각 그룹별로 나누기 & 이상치제거 & 정규화 & 로그변환을 한다음 
마지막에 합치게되면 성능이 올라가는지에 대해 의문.

로그변환을 하게되면 차이가 커지지는 않음.

*극단값에 영향을 받으면 의미가 있을꺼같음. 
시도 해보는게 좋을듯함.

상민님)
노멀데이터를 어떻게 나눠서 성능을 높일수있을까 생각해봄.
머신러닝 모델이 더 잘나옴.
데이터가 특이했던점은 전체적인 문제가 예측값이 실제값에 비해 분산도가 작게나온다는것.
노멀데이터같은 경우에는 y1~ 14까지 비슷
실제값과 예측값의 차이를 줄이는 것이 포인트인거 같다.

커리큘럼 러닝을 했더니 성능이 조금 오름 0.005 정도
쉬운 것 부터 학습 시키자, 배치 순서를 잘 정해놓는것

다른 모델도 더 돌려볼생각

다른대회에서 쓰는 캡부스트 러닝도 써볼 생각

+딥러닝은 좀 아닌거같음 


종원님)
주연님, 상민님 8/14일 발표내용 다시설명 
MultiOutputRgressor는 답이 없다고 느낌 
성능이 더이상 올라가지 않음 
최고로 1.94정도 나오고 그이상으로는 나오지않음 

그래서 생각한게 새로운 변수를 이용해서 파생변수 만들려고함.
변수를 곱하는 것이 성능에 도움을 줄수있다는 연구결과가 있음. 
하나하나 만들어보려고함. y 08 까지는 파생변수를 만들어서 예측해보려고함.
마무리 단계 인거같음

상민님 코드로 돌려봤더니 1.99 정도 나옴
결론 : 의미있는 컬럼만 학습 시키는 것은 별로 의미가 없을 것이다. 결국, 모든 데이터에는 일정한 영향이 있었다. 

xgboost로 계속해서 돌릴려고 한다.  


