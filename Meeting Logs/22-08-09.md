22년 08월 09일 월요일

### 우근님
- 이상치 제거를 시도했음
- 기본, 이상치 제거, 좀 더 휴리스틱하게 이상치 제거 3가지 방법을 비교했는데 큰 차이가 없었음.
- 다른 방법을 모색해야 할 것 같긴함

> 상민
- 아마 이상치 제거가 큰 역할을 하지 못한것 같긴한데 혹시 모르니 모델을 바꿔서 다시 한번 확인 사살(?)을 해보면 좋을 거 같음
- Pycaret결과 LGBMRegressor, GradientBoostingRegressor, RandomForestRegressor 모델이 대부분 컬럼의 성능이 좋았던 상위모델임. 이 모델들로 알아보면 좋을 듯

### 현지님
- 데이터를 딱히 만진것은 없음
- 특정 컬럼을 제거하거나 만들거나 하는 방법 그 외에 전처리 방법들이 필요할 것 같음

### 상민님
- 전처리 4가지(이슈 참고) 했는데 큰 성능 향상 없었음
  - PCA
  - 정규화(정규화는 성능이 조금 오르긴 했음)
  - 의미있는 컬럼만 학습
  - 의미없는 컬럼 제거
- Regressor chain 적용했는데 소용 없었음. 딥러닝에서 다시 해봐야 할듯
- 데이터 분산이 예측이랑 실제랑 너무 다름.. 이 부분 다시 봐봐야 할 듯
- pycaret 계속 돌리고 있고, 아마 이틀 정도 소요될 듯
  - bag, boost, tune
  - blending, stacking
- 딥러닝 모델쪽 시작하겠음

### 종원님
- 성능 실험 결과 필요없는 컬럼은 없다고 판단됨. 아마 대부분 사용해야 할듯
- 다중 공선성 실험 해봤는데 크게 수확 없음
- 이상치 실험 해봤는데 크게 수확 없음
  - 이상치 자체도 학습에 도움이 된다는 의견이 있어서 영향력을 확인해보려고 함
- 파생변수도 사용해 보겠음
