## 22년 08월 11일 목요일

### 상민님


#### 예측 데이터의 분산 분포 조정

#### 실제값과 예측값의 분포 차이

- 예측값의 데이터 분포를 늘려주어서 실제값의 분포를 맞추어 줌.
- 각 분포에 표준편차 평균 구하고 a, b 값 구해서 적용해서 분포는 맞추었다.

하지만 좋은 성능은 나오지 않았다.

그래프에서 예측값은 늘어나게 설정해두었고 실제값도 상민님이 설정한대로 가까워졌다가 멀어지게 설정했지만 
결국 데이터값이 불규칙적으로 그래프를 구성하게 되어 실패로 돌아감.


#### 레이어를 쌓아봄. -> 56차원부터 512까지 만들어보았다. 30층 넘게 쌓기도 해봄. 큰 차이는 없었다. 과적합조차 일어나지 않았다.

- 56에서 14까지도 내려봤지만 큰 차이는 없었다.

이쯤에서 도달한 결론은 딥러닝에서 답이 좀 없을 수도 있겠다.

mlp는 기대했던 건 없었다.


#### 한 가지 알아낸 것

- y값의 스펙 최대최소를 안 봤다가 이제 봄.
- 좀 빠지는 게 있음. 정상 데이터가 35690개였음. -> y스펙 안에 안 들어가는 게 약 4천개

- 빼고 돌려보니 1.7 정도 나옴 WOW  =>  여기서 보물을 발견한 것 같음. 그러나 내보니 1.97 정도 나옴.


#### x로 비정상 y를 찾아낼 수 있지 않을까

성공하려면 2가지

- 분리를 잘 해야 됨.
- 어떻게 훈련을 해야하는가?


---

### 현지님



#### 트레인 테스트 셋 합쳐봄.

- 그러고 나서 전처리를 할 예정

- 결측치 체크

- 컬럼의 개수 파악

- 모든 개수 파악

- 그룹을 나눠볼까 생각

- 컬럼마다 관계있는 것을 기준으로 -> 그러면 어려워짐, 확실하게 모를 것 같아서

#### 안에 있는 요소 단위 개수를 기준으로 1 10 100 1000 10000단위로 묶어봄

- 그룹 3 문자열이 없음
- 실수처럼 많은 숫자를 한자리수로 바꿔보려 함

- 성능을 높이려면 구간화를 높일 거라고 들어서 X_03부터 구간화를 하고 X_05도 해봄.

- 음수도 똑같은 방법으로 하려고 함수를 만들어봄.
- 하지만 오류가 뜸.

#### -> 종원님이 오류 나는 코드 봐주심 결과는 나중에

- 나머지 그룹도 이런 방식으로 할지 고민

- 구간화를 많이 해보려고 함.

- 다른 전처리 방법이 생각나면 또 해볼 생각


종원님은 해보셔서 결과를 알고 있음. 재밌는 결과가 나올 것. 해볼만 한 도전이 될 것.

구간화 자동 라이브러리가 있을 것임.


---

### 종원님


별로 한 게 없음. 하지만 좋아하는 게임을 못 할 정도로 컴퓨터를 사용 중. GPU 가동 100%,  10시간 돌리다가 잠깐 수강신청하는 사이에 중단됐었음.

#### 상민님의 코드에서 아이디어 파이케럿 돌려봄

- XGB부스터가 좋아서 사용하기로 결정.
- 어떤 모델이 더 잘 동작한다만 알려줌.

#### 딥러닝은 파라미터를 조절하는 것이다. -> 그리드 서치를 사용해서 XGB를 최적화하자.

- 다중 아웃풋 MLP리그레서 XGB기르레서
- MLP는 2.00
- XGB 러닝레이트 조절 등 파라미터를 바꿔줌으로써 다양한 실험.

- 864번의 경우를 실험 중.

- 일단 컬럼이 많을수록 좋음.
#### 많은 파생변수를 만드려고 했다. 

- How?
어떤 분이 만들어놓은 그룹에서 각 그룹의 평균, 편차, 합, 표준편차, 중앙값. 그룹별로 새로운 컬럼을 만들어냄. X_57, X_58 등등
대충 60개 정도 만들어놓음. 이미 하고 있는 게 있어서 실행은 못함.

- 한 그룹당 5개의 컬럼. 세어보니 85개의 새로운 컬럼이 만들어짐. 의미없는 그룹이 있어서 25개 빼줌. 60개 맞음.
컬럼을 그리드 서치CV에 넣어줌. 원래있던 60+56-4-5=107의 컬럼을 가지고 아까 288번의 경우를 실험 중. 계속 돌려봐야 하고 기약은 없음.

- 계속 돌려보다보면 학습이 끝나게 될 것임.

최적의 파라미터를 구할 수 있음. 조금이라도 성능을 높이고 싶을 때 이렇게 함. 전기세 많이 나오므로 주의.

이거 다 하고나면 상민님이 제안하신 거 할 수도 있지만 언제 끝날지 모름.

#### +
2년 전에 비슷한 리그레션 한 게 있는데 1등 코드를 가지고 해볼 예정. 혼자 0.7을 찍음. 데이터를 그대로 넣어서 해볼 생각도 있음.


#### 상민님의 생각
- 튜닝을 다른 방식으로 해보면 좋을 것 같다.
시간이 너무 많이 걸리기 때문

- 파이케럿으로 이미 다 지나온 부분. 조금 차이점은 직접 그리드 서치 범위를 정해주었다는 것. 파라미터 정의의 차이는 있는 것 같다.
상민님 - 6일 정도 돌리고 1.9를 벗어나지 못함. 시간이 지날 수록 자신감이 떨어짐.

- 타이밍 좋게 코드 끝남. 파생변수 돌려봤다고 해서 성능이 좋아지진 않음.

- 잘하는 사람들 코드 돌려보는 거 매우 찬성.


---

### 우근님

- 저번에 만든 데이터셋으로 모델 별로 성능을 비교해봄.
- LGBM이 가장 좋았음.

- 다른 사람의 데이터 전처리 방법을 적용해서 x, y feature를 그룹화하여 정규화를 통해 전처리를 해볼 예정.
