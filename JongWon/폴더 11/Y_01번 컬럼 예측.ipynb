{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14): # ignore 'ID'\n",
    "        rmse = metrics.mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    print(all_nrmse[:8])\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 소환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 데이터 소환\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "train_df, valid_df = train_test_split(train_df, train_size=0.8,random_state=42)\n",
    "\n",
    "X_train = train_df.iloc[:,:57].drop([\"ID\",\"X_04\",\"X_23\",\"X_47\",\"X_48\"],axis = 1)\n",
    "y_train = train_df.iloc[:,57]\n",
    "\n",
    "X_test = valid_df.iloc[:,:57].drop([\"ID\",\"X_04\",\"X_23\",\"X_47\",\"X_48\"],axis = 1)\n",
    "y_test = valid_df.iloc[:,57]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross_val_score 돌릴때 데이터 소환\n",
    "# train_df = pd.read_csv('./train.csv')\n",
    "# test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# X_train = train_df.iloc[:,:57].drop([\"ID\",\"X_04\",\"X_23\",\"X_47\",\"X_48\"],axis = 1)\n",
    "# y_train = train_df.iloc[:,57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>...</th>\n",
       "      <th>X_45</th>\n",
       "      <th>X_46</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17963</th>\n",
       "      <td>66.465</td>\n",
       "      <td>103.320</td>\n",
       "      <td>62.57</td>\n",
       "      <td>102.080</td>\n",
       "      <td>67.845</td>\n",
       "      <td>28.91</td>\n",
       "      <td>101.23</td>\n",
       "      <td>260.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1469</td>\n",
       "      <td>12604.63</td>\n",
       "      <td>128.065556</td>\n",
       "      <td>142.927876</td>\n",
       "      <td>143.934663</td>\n",
       "      <td>127.675734</td>\n",
       "      <td>128.842655</td>\n",
       "      <td>134.760060</td>\n",
       "      <td>126.813557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14237</th>\n",
       "      <td>70.544</td>\n",
       "      <td>103.320</td>\n",
       "      <td>78.17</td>\n",
       "      <td>101.929</td>\n",
       "      <td>71.923</td>\n",
       "      <td>28.86</td>\n",
       "      <td>111.90</td>\n",
       "      <td>214.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1469</td>\n",
       "      <td>15321.23</td>\n",
       "      <td>127.643056</td>\n",
       "      <td>133.561871</td>\n",
       "      <td>140.044099</td>\n",
       "      <td>127.529585</td>\n",
       "      <td>126.330578</td>\n",
       "      <td>133.354809</td>\n",
       "      <td>133.543911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.320</td>\n",
       "      <td>68.17</td>\n",
       "      <td>103.136</td>\n",
       "      <td>68.864</td>\n",
       "      <td>28.14</td>\n",
       "      <td>108.46</td>\n",
       "      <td>364.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1469</td>\n",
       "      <td>12411.43</td>\n",
       "      <td>136.358098</td>\n",
       "      <td>129.140545</td>\n",
       "      <td>132.645387</td>\n",
       "      <td>126.858297</td>\n",
       "      <td>124.748920</td>\n",
       "      <td>128.367512</td>\n",
       "      <td>121.985188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18587</th>\n",
       "      <td>74.623</td>\n",
       "      <td>103.320</td>\n",
       "      <td>81.37</td>\n",
       "      <td>103.157</td>\n",
       "      <td>74.983</td>\n",
       "      <td>30.13</td>\n",
       "      <td>376.16</td>\n",
       "      <td>188.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1469</td>\n",
       "      <td>14008.93</td>\n",
       "      <td>131.659291</td>\n",
       "      <td>125.397381</td>\n",
       "      <td>148.744196</td>\n",
       "      <td>131.340460</td>\n",
       "      <td>135.328876</td>\n",
       "      <td>144.221821</td>\n",
       "      <td>130.223950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19112</th>\n",
       "      <td>65.445</td>\n",
       "      <td>103.320</td>\n",
       "      <td>64.57</td>\n",
       "      <td>101.986</td>\n",
       "      <td>67.845</td>\n",
       "      <td>27.11</td>\n",
       "      <td>103.94</td>\n",
       "      <td>223.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1469</td>\n",
       "      <td>10530.03</td>\n",
       "      <td>132.419370</td>\n",
       "      <td>129.721226</td>\n",
       "      <td>143.947633</td>\n",
       "      <td>132.284460</td>\n",
       "      <td>126.447689</td>\n",
       "      <td>146.282254</td>\n",
       "      <td>133.663632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33978</th>\n",
       "      <td>69.524</td>\n",
       "      <td>103.321</td>\n",
       "      <td>65.57</td>\n",
       "      <td>103.134</td>\n",
       "      <td>69.884</td>\n",
       "      <td>29.50</td>\n",
       "      <td>128.35</td>\n",
       "      <td>178.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1469</td>\n",
       "      <td>13561.53</td>\n",
       "      <td>137.524754</td>\n",
       "      <td>131.410183</td>\n",
       "      <td>139.238588</td>\n",
       "      <td>135.518782</td>\n",
       "      <td>124.800785</td>\n",
       "      <td>138.075589</td>\n",
       "      <td>135.456371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22572</th>\n",
       "      <td>72.583</td>\n",
       "      <td>103.320</td>\n",
       "      <td>71.17</td>\n",
       "      <td>103.150</td>\n",
       "      <td>72.943</td>\n",
       "      <td>29.66</td>\n",
       "      <td>102.68</td>\n",
       "      <td>171.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1468</td>\n",
       "      <td>13979.33</td>\n",
       "      <td>121.420750</td>\n",
       "      <td>126.243290</td>\n",
       "      <td>136.164087</td>\n",
       "      <td>122.200575</td>\n",
       "      <td>130.297443</td>\n",
       "      <td>133.995617</td>\n",
       "      <td>125.595280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.320</td>\n",
       "      <td>69.97</td>\n",
       "      <td>103.139</td>\n",
       "      <td>68.864</td>\n",
       "      <td>27.61</td>\n",
       "      <td>220.20</td>\n",
       "      <td>144.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1469</td>\n",
       "      <td>14287.43</td>\n",
       "      <td>130.814908</td>\n",
       "      <td>128.802586</td>\n",
       "      <td>135.012003</td>\n",
       "      <td>125.067930</td>\n",
       "      <td>123.093868</td>\n",
       "      <td>140.852940</td>\n",
       "      <td>118.918759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22194</th>\n",
       "      <td>67.485</td>\n",
       "      <td>103.321</td>\n",
       "      <td>61.87</td>\n",
       "      <td>103.132</td>\n",
       "      <td>67.845</td>\n",
       "      <td>29.39</td>\n",
       "      <td>112.83</td>\n",
       "      <td>202.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1469</td>\n",
       "      <td>12598.63</td>\n",
       "      <td>135.452397</td>\n",
       "      <td>131.939602</td>\n",
       "      <td>139.432458</td>\n",
       "      <td>124.437475</td>\n",
       "      <td>124.588634</td>\n",
       "      <td>135.540692</td>\n",
       "      <td>123.279461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37316</th>\n",
       "      <td>67.485</td>\n",
       "      <td>103.320</td>\n",
       "      <td>64.57</td>\n",
       "      <td>101.958</td>\n",
       "      <td>67.845</td>\n",
       "      <td>27.66</td>\n",
       "      <td>162.97</td>\n",
       "      <td>220.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1469</td>\n",
       "      <td>14235.53</td>\n",
       "      <td>137.314900</td>\n",
       "      <td>132.005718</td>\n",
       "      <td>149.774332</td>\n",
       "      <td>128.601553</td>\n",
       "      <td>127.192715</td>\n",
       "      <td>145.723050</td>\n",
       "      <td>136.890209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7922 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_01     X_02   X_03     X_05    X_06   X_07    X_08    X_09  X_10  \\\n",
       "17963  66.465  103.320  62.57  102.080  67.845  28.91  101.23  260.04   0.0   \n",
       "14237  70.544  103.320  78.17  101.929  71.923  28.86  111.90  214.75   0.0   \n",
       "2992   68.504  103.320  68.17  103.136  68.864  28.14  108.46  364.07   0.0   \n",
       "18587  74.623  103.320  81.37  103.157  74.983  30.13  376.16  188.52   0.0   \n",
       "19112  65.445  103.320  64.57  101.986  67.845  27.11  103.94  223.55   0.0   \n",
       "...       ...      ...    ...      ...     ...    ...     ...     ...   ...   \n",
       "33978  69.524  103.321  65.57  103.134  69.884  29.50  128.35  178.23   0.0   \n",
       "22572  72.583  103.320  71.17  103.150  72.943  29.66  102.68  171.40   0.0   \n",
       "2865   68.504  103.320  69.97  103.139  68.864  27.61  220.20  144.28   0.0   \n",
       "22194  67.485  103.321  61.87  103.132  67.845  29.39  112.83  202.16   0.0   \n",
       "37316  67.485  103.320  64.57  101.958  67.845  27.66  162.97  220.51   0.0   \n",
       "\n",
       "       X_11  ...  X_45  X_46      X_49        X_50        X_51        X_52  \\\n",
       "17963   0.0  ...  0.12  1469  12604.63  128.065556  142.927876  143.934663   \n",
       "14237   0.0  ...  0.12  1469  15321.23  127.643056  133.561871  140.044099   \n",
       "2992    0.0  ...  0.17  1469  12411.43  136.358098  129.140545  132.645387   \n",
       "18587   0.0  ...  0.12  1469  14008.93  131.659291  125.397381  148.744196   \n",
       "19112   0.0  ...  0.16  1469  10530.03  132.419370  129.721226  143.947633   \n",
       "...     ...  ...   ...   ...       ...         ...         ...         ...   \n",
       "33978   0.0  ...  0.13  1469  13561.53  137.524754  131.410183  139.238588   \n",
       "22572   0.0  ...  0.16  1468  13979.33  121.420750  126.243290  136.164087   \n",
       "2865    0.0  ...  0.11  1469  14287.43  130.814908  128.802586  135.012003   \n",
       "22194   0.0  ...  0.12  1469  12598.63  135.452397  131.939602  139.432458   \n",
       "37316   0.0  ...  0.19  1469  14235.53  137.314900  132.005718  149.774332   \n",
       "\n",
       "             X_53        X_54        X_55        X_56  \n",
       "17963  127.675734  128.842655  134.760060  126.813557  \n",
       "14237  127.529585  126.330578  133.354809  133.543911  \n",
       "2992   126.858297  124.748920  128.367512  121.985188  \n",
       "18587  131.340460  135.328876  144.221821  130.223950  \n",
       "19112  132.284460  126.447689  146.282254  133.663632  \n",
       "...           ...         ...         ...         ...  \n",
       "33978  135.518782  124.800785  138.075589  135.456371  \n",
       "22572  122.200575  130.297443  133.995617  125.595280  \n",
       "2865   125.067930  123.093868  140.852940  118.918759  \n",
       "22194  124.437475  124.588634  135.540692  123.279461  \n",
       "37316  128.601553  127.192715  145.723050  136.890209  \n",
       "\n",
       "[7922 rows x 52 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# grid_search 함수를 만듭니다.\n",
    "def grid_search(params, random=False,cv = 5,idx=57):\n",
    "\n",
    "    reg=XGBRegressor(random_state=42,tree_method='gpu_hist', gpu_id=0,verbosity=0)\n",
    "    \n",
    "    if random:\n",
    "        grid_reg = RandomizedSearchCV(reg, params, cv=cv, n_iter=20, \n",
    "                                  n_jobs=-1, random_state=42)\n",
    "    else:\n",
    "        grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    # GridSearchCV 객체를 만듭니다.\n",
    "    \n",
    "    # X_train와 y_train에서 그리드 서치를 수행합니다.\n",
    "    grid_reg.fit(X_train, y_train,eval_set=[(X_test, y_test)],eval_metric='rmse',early_stopping_rounds=30)\n",
    "\n",
    "    # 최상의 매개변수를 추출합니다.\n",
    "    best_params = grid_reg.best_params_\n",
    "\n",
    "    # 최상의 매개변수를 출력합니다.\n",
    "    print(\"최상의 매개변수:\", best_params)\n",
    "    \n",
    "    # 최상의 점수를 계산합니다.\n",
    "    best_score = grid_reg.best_score_/np.mean(np.abs(y_test[:,idx]))\n",
    "\n",
    "    # 최상의 점수를 출력합니다.\n",
    "    print(\"훈련 점수: {:.3f}\".format(best_score))\n",
    "\n",
    "    # 테스트 세트에 대한 예측을 만듭니다.\n",
    "    y_pred = grid_reg.predict(X_test)\n",
    "\n",
    "    # 평균 제곱근 오차를 계산합니다.\n",
    "    nrmse_test = mean_squared_error(y_test, y_pred, squared=False)/np.mean(np.abs(y_test[:,idx]))\n",
    "\n",
    "    # 테스트 세트 점수를 출력합니다.\n",
    "    print('테스트 점수: {:.3f}'.format(nrmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.70672\n",
      "[1]\tvalidation_0-rmse:0.55846\n",
      "[2]\tvalidation_0-rmse:0.46775\n",
      "[3]\tvalidation_0-rmse:0.41540\n",
      "[4]\tvalidation_0-rmse:0.38657\n",
      "[5]\tvalidation_0-rmse:0.37094\n",
      "[6]\tvalidation_0-rmse:0.36278\n",
      "[7]\tvalidation_0-rmse:0.35847\n",
      "[8]\tvalidation_0-rmse:0.35618\n",
      "[9]\tvalidation_0-rmse:0.35493\n",
      "[10]\tvalidation_0-rmse:0.35431\n",
      "[11]\tvalidation_0-rmse:0.35405\n",
      "[12]\tvalidation_0-rmse:0.35397\n",
      "[13]\tvalidation_0-rmse:0.35398\n",
      "[14]\tvalidation_0-rmse:0.35390\n",
      "[15]\tvalidation_0-rmse:0.35388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\(lg_aimers)\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\(lg_aimers)\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\tvalidation_0-rmse:0.35387\n",
      "[17]\tvalidation_0-rmse:0.35395\n",
      "[18]\tvalidation_0-rmse:0.35411\n",
      "[19]\tvalidation_0-rmse:0.35423\n",
      "[20]\tvalidation_0-rmse:0.35411\n",
      "[21]\tvalidation_0-rmse:0.35403\n",
      "[22]\tvalidation_0-rmse:0.35408\n",
      "[23]\tvalidation_0-rmse:0.35393\n",
      "[24]\tvalidation_0-rmse:0.35390\n",
      "최상의 매개변수: {'n_estimators': 25}\n",
      "훈련 점수: 0.349\n",
      "테스트 점수: 0.354\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators':[2, 25, 50, 75, 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.70701\n",
      "[1]\tvalidation_0-rmse:0.55944\n",
      "[2]\tvalidation_0-rmse:0.46922\n",
      "[3]\tvalidation_0-rmse:0.41675\n",
      "[4]\tvalidation_0-rmse:0.38769\n",
      "[5]\tvalidation_0-rmse:0.37212\n",
      "[6]\tvalidation_0-rmse:0.36381\n",
      "[7]\tvalidation_0-rmse:0.35928\n",
      "[8]\tvalidation_0-rmse:0.35683\n",
      "[9]\tvalidation_0-rmse:0.35521\n",
      "[10]\tvalidation_0-rmse:0.35426\n",
      "[11]\tvalidation_0-rmse:0.35352\n",
      "[12]\tvalidation_0-rmse:0.35306\n",
      "[13]\tvalidation_0-rmse:0.35278\n",
      "[14]\tvalidation_0-rmse:0.35261\n",
      "[15]\tvalidation_0-rmse:0.35241\n",
      "[16]\tvalidation_0-rmse:0.35221\n",
      "[17]\tvalidation_0-rmse:0.35207\n",
      "[18]\tvalidation_0-rmse:0.35191\n",
      "[19]\tvalidation_0-rmse:0.35182\n",
      "[20]\tvalidation_0-rmse:0.35176\n",
      "[21]\tvalidation_0-rmse:0.35156\n",
      "[22]\tvalidation_0-rmse:0.35158\n",
      "[23]\tvalidation_0-rmse:0.35147\n",
      "[24]\tvalidation_0-rmse:0.35140\n",
      "[25]\tvalidation_0-rmse:0.35138\n",
      "[26]\tvalidation_0-rmse:0.35136\n",
      "[27]\tvalidation_0-rmse:0.35136\n",
      "[28]\tvalidation_0-rmse:0.35130\n",
      "[29]\tvalidation_0-rmse:0.35127\n",
      "[30]\tvalidation_0-rmse:0.35123\n",
      "[31]\tvalidation_0-rmse:0.35119\n",
      "[32]\tvalidation_0-rmse:0.35120\n",
      "[33]\tvalidation_0-rmse:0.35111\n",
      "[34]\tvalidation_0-rmse:0.35110\n",
      "[35]\tvalidation_0-rmse:0.35106\n",
      "[36]\tvalidation_0-rmse:0.35104\n",
      "[37]\tvalidation_0-rmse:0.35103\n",
      "[38]\tvalidation_0-rmse:0.35107\n",
      "[39]\tvalidation_0-rmse:0.35107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\(lg_aimers)\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\(lg_aimers)\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\tvalidation_0-rmse:0.35097\n",
      "[41]\tvalidation_0-rmse:0.35096\n",
      "[42]\tvalidation_0-rmse:0.35097\n",
      "[43]\tvalidation_0-rmse:0.35097\n",
      "[44]\tvalidation_0-rmse:0.35094\n",
      "[45]\tvalidation_0-rmse:0.35092\n",
      "[46]\tvalidation_0-rmse:0.35095\n",
      "[47]\tvalidation_0-rmse:0.35092\n",
      "[48]\tvalidation_0-rmse:0.35091\n",
      "[49]\tvalidation_0-rmse:0.35091\n",
      "최상의 매개변수: {'max_depth': 2, 'n_estimators': 50}\n",
      "훈련 점수: 0.347\n",
      "테스트 점수: 0.351\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 3, 4, 6, 7, 8], \n",
    "                    'n_estimators':[2, 50, 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'min_child_weight':[ 4, 5,6,7], \n",
    "                    'learning_rate':[0.1,0.05,0.01,0.005,0.001], \n",
    "                    'max_depth':[5,6,7,8, None], \n",
    "                    'n_estimators':[75, 100,150,200,300,500,1000]}, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def my_loss(y_true, y_pred):\n",
    "    # 내가 정의한 손실 함수\n",
    "    error = y_true - y_pred\n",
    "    rmse=tf.math.sqrt(tf.reduce_mean(tf.math.square(error)))\n",
    "    nrmse = rmse/tf.reduce_mean(tf.math.abs (y_true))\n",
    "    return nrmse\n",
    "\n",
    "def my_metric(y_true, y_pred):  \n",
    "    error = y_true - y_pred\n",
    "    rmse=tf.math.sqrt(tf.reduce_mean(tf.math.square(error)))\n",
    "    nrmse = rmse/tf.reduce_mean(tf.math.abs(y_true))\n",
    "    return nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fold = []\n",
    "\n",
    "for train, test in kfold.split(X_train):\n",
    "\n",
    "    model.fit(X_train.loc[train], y_train.loc[train], epochs=20 , batch_size = 64)\n",
    "        \n",
    "    scores = model.evaluate(X_train.loc[test], y_train.loc[test], verbose=0)\n",
    "    loss_fold.append(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('(lg_aimers)')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8229f4c66369636c2f677a0ccad9e09a1901dc8eb305d0fd7a42760bb200be6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
