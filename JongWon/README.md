# 폴더 1
## Y 컬럼별 중요 설명변수 추출 후 개별 모델링
- 1.9746794694의 public score이 나왔다.(baseline code 보다 점수가 낮다.)
# 폴더 2
## 간단한 정규화 후 mlp 진행
- 2.0070917362의 성능이 나왔다.
# 폴더 3
## 간단한 정규화 후 검사 합격 데이터 제거 후 mlp 진행
- 2.0110865911의 성능이 나왔다.

# 폴더 4

## group 화한 설명변수를 차례로 빼고 학습 진행

- xgboost의 자체성능으로 LB는 1.94가 나왔음

# 폴더 5

## pycaret을 사용한 머신러닝

- 일단 한번 해봐야 할것 같아서 진행중
- 기본 pycaret 실습+ 결과에 소수점 2번째 자리까지 반올림 후 제출
- LB값 ![image-20220810153505845](D:\다운로드\image-20220810153505845.png)



# 폴더 6

## 파생변수 잔뜩생성

파생변수 60개 생성해서 train 데이터에 넣기

## 파생변수 잔뜩 생성 후 mlp와 xgboost 돌려보기

116개의 파생변수로 GridSearchCV MultiOutputRegressor 돌려서 제출해보기

![image-20220810153505845](https://user-images.githubusercontent.com/76269640/184179502-44b3cc24-9f1e-40e0-997a-4822de73c3ca.png)

결과는 이러함

# 폴더7

## 상민님의 결과에 보탬이 되기위한 시각화

- 이상치들을 y 컬럼별로 정리하였음

## 간단한 사용예제

- y컬럼별로 메타데이터에 들어가 있지 않은 데이터들은 행별로 삭제
- 걸러진 데이터로 모델생성후 train 데이터 전체로 score 확인 ====> 1.7355972148727803
- 하지만 리더보드는 성능이 않좋음
- ![image](https://user-images.githubusercontent.com/76269640/184179157-c000a296-c01d-419b-9743-9b8ede1dc346.png)
